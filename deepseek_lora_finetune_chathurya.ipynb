{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cfc81183ed7d453ebce3dd7219686f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6abb455ef7e84877b383b320dca2d40f",
              "IPY_MODEL_3a99b7c23f9c42e79b56d633ef0190e3",
              "IPY_MODEL_7fc8885f5a954b4c8efae3c6a3454cd1"
            ],
            "layout": "IPY_MODEL_76ff5d4416f14e7ebbf0c91fca4cfc90"
          }
        },
        "6abb455ef7e84877b383b320dca2d40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3b4fda2f03c490f9688d367e79ed70a",
            "placeholder": "​",
            "style": "IPY_MODEL_9c96e47183ba436695c709b4836808cc",
            "value": "Tokenising dataset: 100%"
          }
        },
        "3a99b7c23f9c42e79b56d633ef0190e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_288421101b98474ebb26ed5d6f58f3b5",
            "max": 104,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_337b23ad803b45428f178297bfbab549",
            "value": 104
          }
        },
        "7fc8885f5a954b4c8efae3c6a3454cd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_770e9a3f63184cec8a185997bc7c1fbd",
            "placeholder": "​",
            "style": "IPY_MODEL_3aa13995d1b4435b9a007c9da60a30e8",
            "value": " 104/104 [00:01&lt;00:00, 68.75 examples/s]"
          }
        },
        "76ff5d4416f14e7ebbf0c91fca4cfc90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3b4fda2f03c490f9688d367e79ed70a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c96e47183ba436695c709b4836808cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "288421101b98474ebb26ed5d6f58f3b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "337b23ad803b45428f178297bfbab549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "770e9a3f63184cec8a185997bc7c1fbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aa13995d1b4435b9a007c9da60a30e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets peft accelerate"
      ],
      "metadata": {
        "id": "W6elH6jZt1V3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, os, json, shutil\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from datasets import Dataset as HFDataset\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Starting DeepSeek LoRA Fine-tuning …\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXkV5vz3t3LD",
        "outputId": "9dd91a4c-600e-4e86-a970-b9e7aecc08e4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting DeepSeek LoRA Fine-tuning …\n",
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Please upload your dataset.jsonl file:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "uploaded = files.upload()\n",
        "dataset_file = None\n",
        "for fname in uploaded:\n",
        "    if fname.endswith(\".jsonl\"):\n",
        "        if fname != \"dataset.jsonl\":\n",
        "            os.rename(fname, \"dataset.jsonl\")\n",
        "        dataset_file = \"dataset.jsonl\"\n",
        "        break\n",
        "if dataset_file is None:\n",
        "    raise ValueError(\"No .jsonl file uploaded!\")\n",
        "\n",
        "with open(dataset_file) as f:\n",
        "    rows = [ln for ln in f if ln.strip()]\n",
        "print(f\"\\n✓ Uploaded {dataset_file}  — {len(rows)} examples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "9FYGTUIdt44O",
        "outputId": "223ba2c8-56f3-4f06-df82-96b03f7c8e28"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Please upload your dataset.jsonl file:\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8fbc977d-96de-4ab7-899b-344a249d33f0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8fbc977d-96de-4ab7-899b-344a249d33f0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset.jsonl to dataset (1).jsonl\n",
            "\n",
            "✓ Uploaded dataset.jsonl  — 104 examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "with open(dataset_file) as f:\n",
        "    for idx, ln in enumerate(f, 1):\n",
        "        if ln.strip():\n",
        "            try:\n",
        "                data.append(json.loads(ln))\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(\"Skip line\", idx, e)\n",
        "dataset = HFDataset.from_list(data)\n",
        "print(\"Columns:\", dataset.column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgHtOH-ct86k",
        "outputId": "3d9643a0-d28b-44c8-b33b-eacd25f3a027"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns: ['instruction', 'output']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "special_tokens = {\n",
        "    \"additional_special_tokens\": [\n",
        "        \"<disaster_analysis>\", \"</disaster_analysis>\",\n",
        "        \"<event_summary>\", \"</event_summary>\",\n",
        "        \"<detailed_analysis>\", \"</detailed_analysis>\",\n",
        "        \"<predictions>\", \"</predictions>\",\n",
        "        \"<impacts>\", \"</impacts>\",\n",
        "        \"<mitigation_strategies>\", \"</mitigation_strategies>\",\n",
        "        \"<recommendations>\", \"</recommendations>\",\n",
        "    ]\n",
        "}\n",
        "tokenizer.add_special_tokens(special_tokens)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name, torch_dtype=torch.float16, device_map=\"auto\"\n",
        ")\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "print(\"Model & tokenizer loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OS7vSfHWt_MH",
        "outputId": "87c3c1dd-7421-45fd-96b9-3fd376bee979"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model & tokenizer loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lora_cfg = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "model = get_peft_model(model, lora_cfg)\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hcr3kmLRuBWa",
        "outputId": "df46ab3c-ee5a-4106-fd0f-8932980ba1a4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 2,179,072 || all params: 1,778,477,568 || trainable%: 0.1225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = (\n",
        "    \"You are a helpful assistant trained to provide detailed, structured disaster analysis reports. \"\n",
        "    \"Output exactly these 7 sections without duplication or extra content, using structured text with \"\n",
        "    \"angle-bracket headers (<disaster_analysis>, <event_summary>, etc.). Sections: \"\n",
        "    \"<disaster_analysis> (13 subsections), <event_summary>, <detailed_analysis>, \"\n",
        "    \"<predictions>, <impacts>, <mitigation_strategies>, <recommendations>. \"\n",
        "    \"Do not output JSON.\"\n",
        ")\n",
        "\n",
        "def format_batch(ex):\n",
        "    text = [\n",
        "        f\"{system_prompt}\\n\\nInstruction: {i}\\n\\nResponse:\\n{o}\"\n",
        "        for i, o in zip(ex[\"instruction\"], ex[\"output\"])\n",
        "    ]\n",
        "    tok = tokenizer(\n",
        "        text, max_length=1024, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
        "    )\n",
        "    tok[\"labels\"] = tok[\"input_ids\"].clone()\n",
        "    return tok\n",
        "\n",
        "tok_ds = dataset.map(\n",
        "    format_batch,\n",
        "    batched=True,\n",
        "    remove_columns=dataset.column_names,\n",
        "    desc=\"Tokenising dataset\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "cfc81183ed7d453ebce3dd7219686f11",
            "6abb455ef7e84877b383b320dca2d40f",
            "3a99b7c23f9c42e79b56d633ef0190e3",
            "7fc8885f5a954b4c8efae3c6a3454cd1",
            "76ff5d4416f14e7ebbf0c91fca4cfc90",
            "b3b4fda2f03c490f9688d367e79ed70a",
            "9c96e47183ba436695c709b4836808cc",
            "288421101b98474ebb26ed5d6f58f3b5",
            "337b23ad803b45428f178297bfbab549",
            "770e9a3f63184cec8a185997bc7c1fbd",
            "3aa13995d1b4435b9a007c9da60a30e8"
          ]
        },
        "id": "n9tf2Ip9uEcm",
        "outputId": "0d7f1c2c-6281-47ce-fda3-27f6b0d2a9a7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenising dataset:   0%|          | 0/104 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfc81183ed7d453ebce3dd7219686f11"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./deepseek-lora-output\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    warmup_steps=10,\n",
        "    learning_rate=2e-5,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    logging_steps=5,\n",
        "    save_steps=20,\n",
        "    save_total_limit=2,\n",
        "    remove_unused_columns=False,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tok_ds,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "steps = (len(tok_ds) //\n",
        "         (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps)\n",
        "         * training_args.num_train_epochs)\n",
        "print(\"Total training steps:\", steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrprkUteuJw8",
        "outputId": "1f218beb-8952-4ddd-dc27-54bdaf9f7f9e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-322632901>:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training steps: 78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "trainer.train()\n",
        "print(\"✓ Training complete\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "id": "dNZvx_UBuLu_",
        "outputId": "1afa05d3-6d22-41e6-f894-850a316de457"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='78' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [78/78 03:31, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.266700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.283900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>2.278800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.244300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>2.219900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2.205200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>2.219000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.210800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>2.186500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.195400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>2.210200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>2.188400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>2.191900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>2.185300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>2.150800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Training complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_dir = \"./deepseek-lora-final\"\n",
        "model.save_pretrained(out_dir)\n",
        "tokenizer.save_pretrained(out_dir)\n",
        "print(\"Saved to\", out_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMXqZkT4uO0I",
        "outputId": "7fbb000c-0e7e-4c6a-d538-aae9c9de590a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to ./deepseek-lora-final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Testing model (forced tag prefix)…\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "required_tags = [\n",
        "    \"<disaster_analysis>\", \"<event_summary>\", \"<detailed_analysis>\",\n",
        "    \"<predictions>\", \"<impacts>\", \"<mitigation_strategies>\", \"<recommendations>\",\n",
        "]\n",
        "\n",
        "def gen(instr, max_new=1200):\n",
        "    prompt = f\"{system_prompt}\\n\\nInstruction: {instr}\\n\\nResponse:\\n<disaster_analysis>\"\n",
        "    inp = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(\n",
        "            **inp,\n",
        "            max_new_tokens=max_new,\n",
        "            temperature=0.2,\n",
        "            top_p=0.8,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "    return tokenizer.decode(out[0], skip_special_tokens=False)\n",
        "\n",
        "tests = [\n",
        "    \"Analyze the potential impact of a Category 5 hurricane hitting Miami, Florida.\",\n",
        "    \"Evaluate the risks and provide analysis for a major earthquake in Los Angeles.\",\n",
        "    \"Assess the disaster preparedness for flooding in a coastal city.\",\n",
        "]\n",
        "\n",
        "for n, t in enumerate(tests, 1):\n",
        "    print(f\"\\nTest {n}: {t}\")\n",
        "    print(\"-\"*110)\n",
        "    reply = gen(t)\n",
        "    print(reply[:2000] + (\" …[truncated]\" if len(reply) > 2000 else \"\"))\n",
        "\n",
        "    found = [tag for tag in required_tags if tag in reply]\n",
        "    print(f\"\\n✓ Found {len(found)}/{len(required_tags)} tags → {found}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_3xwjAfuQ9X",
        "outputId": "c4df745c-ea46-49ec-b0d7-50bda91cc032"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Testing model (forced tag prefix)…\n",
            "==================================================\n",
            "\n",
            "Test 1: Analyze the potential impact of a Category 5 hurricane hitting Miami, Florida.\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "<｜begin▁of▁sentence｜>You are a helpful assistant trained to provide detailed, structured disaster analysis reports. Output exactly these 7 sections without duplication or extra content, using structured text with angle-bracket headers (<disaster_analysis>, <event_summary>, etc.). Sections: <disaster_analysis> (13 subsections), <event_summary>, <detailed_analysis>, <predictions>, <impacts>, <mitigation_strategies>, <recommendations>. Do not output JSON.\n",
            "\n",
            "Instruction: Analyze the potential impact of a Category 5 hurricane hitting Miami, Florida.\n",
            "\n",
            "Response:\n",
            "<disaster_analysis>, 13 subsections.\n",
            "\n",
            "1. **Potential Category 5 hurricane impact on Miami**\n",
            "   - **1.1. Historical hurricane frequency and intensity in Miami**\n",
            "     - Analysis of past hurricane events, including their frequency and intensity, to assess the likelihood of a Category 5 hurricane.\n",
            "   - **1.2. Climate change and its effects on Miami**\n",
            "     - Evaluation of how climate change has influenced Miami's climate, including potential shifts in hurricane intensity and frequency.\n",
            "   - **1.3. Oceanographic factors affecting hurricane formation**\n",
            "     - Examination of oceanographic conditions, such as sea surface temperature and wind patterns, that influence hurricane formation.\n",
            "   - **1.4. Weather systems and their potential intensity**\n",
            "     - Analysis of current weather systems in Miami, including potential for a Category 5 hurricane, and their impact on the city.\n",
            "   - **1.5. Oceanic and atmospheric interactions**\n",
            "     - Evaluation of interactions between the ocean and atmosphere that could lead to a Category 5 hurricane.\n",
            "   - **1.6. Local infrastructure and response**\n",
            "     - Assessment of local infrastructure in Miami, such as roads, utilities, and buildings, and their response to a potential Category 5 hurricane.\n",
            "   - **1.7. Public safety and emergency preparedness**\n",
            "     - Analysis of public safety concerns and preparedness measures in place for a potential Category 5 hurricane in Miami.\n",
            "   - **1.8. Economic and …[truncated]\n",
            "\n",
            "✓ Found 7/7 tags → ['<disaster_analysis>', '<event_summary>', '<detailed_analysis>', '<predictions>', '<impacts>', '<mitigation_strategies>', '<recommendations>']\n",
            "\n",
            "Test 2: Evaluate the risks and provide analysis for a major earthquake in Los Angeles.\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "<｜begin▁of▁sentence｜>You are a helpful assistant trained to provide detailed, structured disaster analysis reports. Output exactly these 7 sections without duplication or extra content, using structured text with angle-bracket headers (<disaster_analysis>, <event_summary>, etc.). Sections: <disaster_analysis> (13 subsections), <event_summary>, <detailed_analysis>, <predictions>, <impacts>, <mitigation_strategies>, <recommendations>. Do not output JSON.\n",
            "\n",
            "Instruction: Evaluate the risks and provide analysis for a major earthquake in Los Angeles.\n",
            "\n",
            "Response:\n",
            "<disaster_analysis>, 1. Major earthquake in Los Angeles: The primary risk is the earthquake itself, which has a significant impact on infrastructure, human life, and property. The magnitude of the earthquake is estimated to be around 7.0, which is extremely dangerous. The risk of loss of life is high, with the potential for immediate fatalities. The risk of damage to buildings and infrastructure is also significant, with the possibility of significant damage to homes, bridges, and other structures. The risk of loss of property is high, with the potential for significant damage to personal and business assets. The risk of loss of life is high, with the potential for immediate fatalities. The risk of loss of property is high, with the potential for significant damage to personal and business assets. The risk of loss of life is high, with the potential for immediate fatalities. The risk of loss of property is high, with the potential for significant damage to personal and business assets. The risk of loss of life is high, with the potential for immediate fatalities. The risk of loss of property is high, with the potential for significant damage to personal and business assets. The risk of loss of life is high, with the potential for immediate fatalities. The risk of loss of property is high, with the potential for significant damage to personal and business assets. The risk of loss of life is high, with the potential f …[truncated]\n",
            "\n",
            "✓ Found 7/7 tags → ['<disaster_analysis>', '<event_summary>', '<detailed_analysis>', '<predictions>', '<impacts>', '<mitigation_strategies>', '<recommendations>']\n",
            "\n",
            "Test 3: Assess the disaster preparedness for flooding in a coastal city.\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "<｜begin▁of▁sentence｜>You are a helpful assistant trained to provide detailed, structured disaster analysis reports. Output exactly these 7 sections without duplication or extra content, using structured text with angle-bracket headers (<disaster_analysis>, <event_summary>, etc.). Sections: <disaster_analysis> (13 subsections), <event_summary>, <detailed_analysis>, <predictions>, <impacts>, <mitigation_strategies>, <recommendations>. Do not output JSON.\n",
            "\n",
            "Instruction: Assess the disaster preparedness for flooding in a coastal city.\n",
            "\n",
            "Response:\n",
            "<disaster_analysis> (13 subsections)\n",
            "\n",
            "1. **Preparedness and Response**\n",
            "   - **Floodplain Mapping**: Detailed maps of floodplain areas to identify high-risk zones.\n",
            "   - **Emergency Response Plan**: Comprehensive plan including evacuation routes, flood suppression measures, and communication protocols.\n",
            "   - **Flood Risk Assessment**: Analysis of flood risk factors, including sea-level rise and coastal erosion.\n",
            "   - **Emergency Response Training**: Training programs for emergency responders to ensure effective response.\n",
            "   - **Flood Management Plan**: Detailed flood management strategies, including drainage systems and emergency response plans.\n",
            "   - **Floodplain Decontamination**: Procedures for decontamination of floodplain areas to prevent further flooding.\n",
            "   - **Floodplain Decontamination Response**: Response plan for decontamination efforts, including communication and coordination.\n",
            "   - **Floodplain Decontamination Funding**: Funding sources for decontamination efforts, including grants and local funds.\n",
            "   - **Floodplain Decontamination Budget**: Budget allocation for decontamination efforts, including personnel, materials, and equipment.\n",
            "   - **Floodplain Decontamination Completion**: Completion timeline for decontamination efforts, including milestones and timelines.\n",
            "   - **Floodplain Decontamination Completion Funding**: Funding sources for decontamination completion, including grants and local funds.\n",
            "   - **Floodplain Deco …[truncated]\n",
            "\n",
            "✓ Found 7/7 tags → ['<disaster_analysis>', '<event_summary>', '<detailed_analysis>', '<predictions>', '<impacts>', '<mitigation_strategies>', '<recommendations>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_name = \"deepseek-lora-final\"\n",
        "shutil.make_archive(zip_name, \"zip\", out_dir)\n",
        "files.download(zip_name + \".zip\")\n",
        "print(\"Model zipped & download triggered\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oiI-6tJLw30M",
        "outputId": "080ccd1d-1ecb-4fea-c1a0-66f33fff0638"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f4b27da4-d7bd-46c6-9578-692e607641cf\", \"deepseek-lora-final.zip\", 723948205)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model zipped & download triggered\n"
          ]
        }
      ]
    }
  ]
}